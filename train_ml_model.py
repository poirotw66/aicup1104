#!/usr/bin/env python3
"""
ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´
è§£æ±ºè³‡æ–™æ´©æ¼å•é¡Œï¼Œä½¿ç”¨é©ç•¶çš„è¨“ç·´/æ¸¬è©¦åˆ†é›¢
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
import joblib
import json
import warnings
warnings.filterwarnings('ignore')


def load_data():
    """è¼‰å…¥è³‡æ–™"""
    print("="*70)
    print("è¼‰å…¥è³‡æ–™...")
    print("="*70)
    
    # è¼‰å…¥ç‰¹å¾µ
    features_df = pd.read_csv('output/features.csv')
    print(f"ç¸½ç‰¹å¾µæ•¸: {len(features_df):,} å¸³æˆ¶, {len(features_df.columns)-1} ç‰¹å¾µ")
    
    # è¼‰å…¥æ¨™ç±¤
    alert_df = pd.read_csv('raw_data/acct_alert.csv')
    alert_accounts = set(alert_df['acct'].values)
    print(f"ç•°å¸¸å¸³æˆ¶æ•¸: {len(alert_accounts):,}")
    
    # è¼‰å…¥é æ¸¬ç›®æ¨™
    predict_df = pd.read_csv('raw_data/acct_predict.csv')
    predict_accounts = set(predict_df['acct'].values)
    print(f"é æ¸¬ç›®æ¨™æ•¸: {len(predict_accounts):,}")
    
    return features_df, alert_accounts, predict_accounts


def prepare_training_data(features_df, alert_accounts, predict_accounts, normal_sample_size=5000):
    """
    æº–å‚™è¨“ç·´è³‡æ–™ï¼ˆä¸åŒ…å«é æ¸¬ç›®æ¨™ï¼Œé¿å…è³‡æ–™æ´©æ¼ï¼‰
    
    Args:
        features_df: ç‰¹å¾µè³‡æ–™
        alert_accounts: ç•°å¸¸å¸³æˆ¶é›†åˆ
        predict_accounts: é æ¸¬ç›®æ¨™é›†åˆ
        normal_sample_size: æ­£å¸¸æ¨£æœ¬æ•¸é‡
    """
    print("\n" + "="*70)
    print("æº–å‚™è¨“ç·´è³‡æ–™ï¼ˆä¿®æ­£è³‡æ–™æ´©æ¼å•é¡Œï¼‰...")
    print("="*70)
    
    # 1. åˆ†é›¢ç•°å¸¸å¸³æˆ¶
    alert_df = features_df[features_df['acct'].isin(alert_accounts)].copy()
    print(f"\nç•°å¸¸æ¨£æœ¬: {len(alert_df):,}")
    
    # 2. æ‰¾å‡ºå¯ç”¨çš„æ­£å¸¸å¸³æˆ¶ï¼ˆæ’é™¤é æ¸¬ç›®æ¨™ï¼‰
    available_normal = features_df[
        ~features_df['acct'].isin(alert_accounts) &
        ~features_df['acct'].isin(predict_accounts)
    ].copy()
    print(f"å¯ç”¨æ­£å¸¸æ¨£æœ¬: {len(available_normal):,}")
    
    # 3. å¾æ­£å¸¸å¸³æˆ¶ä¸­æŠ½æ¨£
    if len(available_normal) > normal_sample_size:
        normal_sample = available_normal.sample(n=normal_sample_size, random_state=42)
    else:
        normal_sample = available_normal
    print(f"æŠ½æ¨£æ­£å¸¸æ¨£æœ¬: {len(normal_sample):,}")
    
    # 4. åˆä½µè¨“ç·´é›†
    train_df = pd.concat([alert_df, normal_sample], ignore_index=True)
    train_df['label'] = train_df['acct'].isin(alert_accounts).astype(int)
    
    # 5. æº–å‚™ç‰¹å¾µå’Œæ¨™ç±¤
    feature_cols = [col for col in train_df.columns if col not in ['acct', 'label', 'is_alert']]
    X_train = train_df[feature_cols]
    y_train = train_df['label']
    
    print(f"\nè¨“ç·´é›†çµ±è¨ˆ:")
    print(f"  ç¸½æ¨£æœ¬: {len(train_df):,}")
    print(f"  ç•°å¸¸: {y_train.sum():,} ({y_train.sum()/len(y_train)*100:.2f}%)")
    print(f"  æ­£å¸¸: {len(y_train)-y_train.sum():,} ({(len(y_train)-y_train.sum())/len(y_train)*100:.2f}%)")
    print(f"  ç‰¹å¾µæ•¸: {len(feature_cols)}")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰è³‡æ–™æ´©æ¼
    leak_check = train_df['acct'].isin(predict_accounts).sum()
    if leak_check > 0:
        print(f"\nâš ï¸  è­¦å‘Š: è¨“ç·´é›†ä¸­æœ‰ {leak_check} å€‹é æ¸¬ç›®æ¨™å¸³æˆ¶ï¼")
    else:
        print(f"\nâœ… ç¢ºèª: è¨“ç·´é›†ä¸­æ²’æœ‰é æ¸¬ç›®æ¨™å¸³æˆ¶")
    
    return X_train, y_train, train_df, feature_cols


def train_models(X_train, y_train, feature_cols):
    """è¨“ç·´å¤šå€‹æ¨¡å‹ä¸¦æ¯”è¼ƒ"""
    print("\n" + "="*70)
    print("è¨“ç·´æ¨¡å‹...")
    print("="*70)
    
    models = {}
    cv_results = {}
    
    # è¨­å®šäº¤å‰é©—è­‰
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    # æ¨¡å‹ 1: Random Forest
    print("\n1ï¸âƒ£  Random Forest...")
    rf = RandomForestClassifier(
        n_estimators=200,
        max_depth=15,
        min_samples_leaf=5,
        min_samples_split=10,
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )
    
    rf_scores = cross_val_score(rf, X_train, y_train, cv=cv, scoring='f1')
    print(f"   CV F1-Score: {rf_scores.mean():.4f} (+/- {rf_scores.std():.4f})")
    
    rf.fit(X_train, y_train)
    models['random_forest'] = rf
    cv_results['random_forest'] = rf_scores
    
    # æ¨¡å‹ 2: Gradient Boosting
    print("\n2ï¸âƒ£  Gradient Boosting...")
    gb = GradientBoostingClassifier(
        n_estimators=200,
        max_depth=8,
        learning_rate=0.05,
        min_samples_leaf=5,
        subsample=0.8,
        random_state=42
    )
    
    gb_scores = cross_val_score(gb, X_train, y_train, cv=cv, scoring='f1')
    print(f"   CV F1-Score: {gb_scores.mean():.4f} (+/- {gb_scores.std():.4f})")
    
    gb.fit(X_train, y_train)
    models['gradient_boosting'] = gb
    cv_results['gradient_boosting'] = gb_scores
    
    # æ¨¡å‹ 3: Random Forest (æ›´ä¿å®ˆ)
    print("\n3ï¸âƒ£  Random Forest (Conservative)...")
    rf_cons = RandomForestClassifier(
        n_estimators=200,
        max_depth=10,
        min_samples_leaf=10,
        min_samples_split=20,
        class_weight='balanced_subsample',
        random_state=42,
        n_jobs=-1
    )
    
    rf_cons_scores = cross_val_score(rf_cons, X_train, y_train, cv=cv, scoring='f1')
    print(f"   CV F1-Score: {rf_cons_scores.mean():.4f} (+/- {rf_cons_scores.std():.4f})")
    
    rf_cons.fit(X_train, y_train)
    models['rf_conservative'] = rf_cons
    cv_results['rf_conservative'] = rf_cons_scores
    
    # é¸æ“‡æœ€ä½³æ¨¡å‹
    best_model_name = max(cv_results, key=lambda k: cv_results[k].mean())
    best_model = models[best_model_name]
    best_score = cv_results[best_model_name].mean()
    
    print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (CV F1: {best_score:.4f})")
    
    return best_model, best_model_name, models, cv_results, feature_cols


def evaluate_on_training(model, X_train, y_train):
    """åœ¨è¨“ç·´é›†ä¸Šè©•ä¼°ï¼ˆç”¨æ–¼æª¢æŸ¥éæ“¬åˆï¼‰"""
    print("\n" + "="*70)
    print("è¨“ç·´é›†è©•ä¼°...")
    print("="*70)
    
    y_pred = model.predict(X_train)
    y_proba = model.predict_proba(X_train)[:, 1]
    
    print(f"\nPrecision: {precision_score(y_train, y_pred):.4f}")
    print(f"Recall: {recall_score(y_train, y_pred):.4f}")
    print(f"F1-Score: {f1_score(y_train, y_pred):.4f}")
    
    cm = confusion_matrix(y_train, y_pred)
    print(f"\nConfusion Matrix:")
    print(f"  TN: {cm[0][0]:,}, FP: {cm[0][1]:,}")
    print(f"  FN: {cm[1][0]:,}, TP: {cm[1][1]:,}")
    
    return {
        'precision': precision_score(y_train, y_pred),
        'recall': recall_score(y_train, y_pred),
        'f1_score': f1_score(y_train, y_pred),
        'confusion_matrix': cm.tolist()
    }


def predict_and_save(model, features_df, predict_accounts, feature_cols, output_path='output/predictions_ml.csv'):
    """å°é æ¸¬ç›®æ¨™é€²è¡Œé æ¸¬"""
    print("\n" + "="*70)
    print("ç”Ÿæˆé æ¸¬...")
    print("="*70)
    
    # ç¯©é¸é æ¸¬ç›®æ¨™
    predict_df = features_df[features_df['acct'].isin(predict_accounts)].copy()
    print(f"é æ¸¬ç›®æ¨™æ•¸: {len(predict_df):,}")
    
    # æº–å‚™ç‰¹å¾µ
    X_pred = predict_df[feature_cols]
    
    # é æ¸¬
    y_pred = model.predict(X_pred)
    y_proba = model.predict_proba(X_pred)[:, 1]
    
    # ä¿å­˜çµæœ
    result_df = pd.DataFrame({
        'acct': predict_df['acct'].values,
        'label': y_pred,
        'confidence_score': y_proba
    })
    
    result_df.to_csv(output_path, index=False)
    print(f"\nâœ… é æ¸¬çµæœå·²ä¿å­˜: {output_path}")
    
    # çµ±è¨ˆ
    n_alert = result_df['label'].sum()
    print(f"\né æ¸¬çµ±è¨ˆ:")
    print(f"  é æ¸¬ç‚ºç•°å¸¸: {n_alert:,} ({n_alert/len(result_df)*100:.2f}%)")
    print(f"  é æ¸¬ç‚ºæ­£å¸¸: {len(result_df)-n_alert:,} ({(len(result_df)-n_alert)/len(result_df)*100:.2f}%)")
    print(f"  å¹³å‡ä¿¡å¿ƒåˆ†æ•¸: {result_df['confidence_score'].mean():.4f}")
    
    # ä¹Ÿç”Ÿæˆç°¡åŒ–ç‰ˆ
    simple_output = output_path.replace('.csv', '_acct_label.csv')
    result_df[['acct', 'label']].to_csv(simple_output, index=False)
    print(f"âœ… ç°¡åŒ–ç‰ˆå·²ä¿å­˜: {simple_output}")
    
    return result_df


def analyze_feature_importance(model, feature_cols, top_n=20):
    """åˆ†æç‰¹å¾µé‡è¦æ€§"""
    print("\n" + "="*70)
    print(f"Top {top_n} é‡è¦ç‰¹å¾µ:")
    print("="*70)
    
    if hasattr(model, 'feature_importances_'):
        importance_df = pd.DataFrame({
            'feature': feature_cols,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\n" + importance_df.head(top_n).to_string(index=False))
        
        importance_df.to_csv('output/ml_feature_importance.csv', index=False)
        print(f"\nâœ… ç‰¹å¾µé‡è¦æ€§å·²ä¿å­˜: output/ml_feature_importance.csv")
        
        return importance_df
    else:
        print("æ¨¡å‹ä¸æ”¯æ´ç‰¹å¾µé‡è¦æ€§åˆ†æ")
        return None


def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "="*70)
    print("ğŸ”§ ä¿®æ­£ç‰ˆæ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´")
    print("   è§£æ±ºè³‡æ–™æ´©æ¼å•é¡Œ")
    print("="*70)
    
    # 1. è¼‰å…¥è³‡æ–™
    features_df, alert_accounts, predict_accounts = load_data()
    
    # 2. æº–å‚™è¨“ç·´è³‡æ–™ï¼ˆä¸åŒ…å«é æ¸¬ç›®æ¨™ï¼‰
    X_train, y_train, train_df, feature_cols = prepare_training_data(
        features_df, alert_accounts, predict_accounts,
        normal_sample_size=5000  # å¯èª¿æ•´
    )
    
    # 3. è¨“ç·´æ¨¡å‹
    best_model, best_model_name, all_models, cv_results, feature_cols = train_models(
        X_train, y_train, feature_cols
    )
    
    # 4. è©•ä¼°è¨“ç·´é›†è¡¨ç¾
    train_metrics = evaluate_on_training(best_model, X_train, y_train)
    
    # 5. åˆ†æç‰¹å¾µé‡è¦æ€§
    importance_df = analyze_feature_importance(best_model, feature_cols)
    
    # 6. å°é æ¸¬ç›®æ¨™é€²è¡Œé æ¸¬
    result_df = predict_and_save(
        best_model, features_df, predict_accounts, feature_cols,
        output_path='output/predictions_ml.csv'
    )
    
    # 7. ä¿å­˜æ¨¡å‹
    model_path = 'output/trained_model.pkl'
    joblib.dump({
        'model': best_model,
        'model_name': best_model_name,
        'feature_cols': feature_cols,
        'train_metrics': train_metrics,
        'cv_results': {k: v.tolist() for k, v in cv_results.items()}
    }, model_path)
    print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # 8. ç”Ÿæˆå ±å‘Š
    report = {
        'model_name': best_model_name,
        'cv_f1_mean': float(cv_results[best_model_name].mean()),
        'cv_f1_std': float(cv_results[best_model_name].std()),
        'train_metrics': {k: float(v) if isinstance(v, (int, float, np.number)) else v 
                         for k, v in train_metrics.items()},
        'n_features': len(feature_cols),
        'n_train_samples': len(X_train),
        'n_train_alerts': int(y_train.sum()),
        'n_predictions': len(result_df),
        'n_predicted_alerts': int(result_df['label'].sum()),
        'prediction_rate': float(result_df['label'].sum() / len(result_df))
    }
    
    with open('output/ml_training_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    print(f"âœ… è¨“ç·´å ±å‘Šå·²ä¿å­˜: output/ml_training_report.json")
    
    print("\n" + "="*70)
    print("âœ¨ è¨“ç·´å®Œæˆï¼")
    print("="*70)
    print(f"\nå»ºè­°ä¸Šå‚³: output/predictions_ml_acct_label.csv")
    print(f"é æœŸ F1-Score æ‡‰è©²æœƒå¤§å¹…æå‡ï¼ˆå¾ 0.07 åˆ° 0.25+ï¼‰")
    
    return best_model, result_df


if __name__ == "__main__":
    best_model, result_df = main()

