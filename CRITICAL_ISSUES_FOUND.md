# ğŸš¨ æ¨¡å‹è¨“ç·´å•é¡Œè¨ºæ–·å ±å‘Š

## æ ¸å¿ƒå•é¡Œï¼šè¨“ç·´é›†éå¤§å°è‡´åš´é‡çš„æ•¸æ“šæ´©æ¼

### å•é¡Œ 1: è¨“ç·´è³‡æ–™åŒ…å«é æ¸¬ç›®æ¨™ âŒ

**ç™¼ç¾ï¼š**
```
rule_evaluation.json:
- n_true_alerts: 945  (è¨“ç·´æ™‚æ¨™è¨˜ç‚ºç•°å¸¸)
- n_predicted_alerts: 45,086 

ä½†å¯¦éš›ä¸Šï¼š
- acct_alert.csv åªæœ‰ 1,004 ç­†ç•°å¸¸å¸³æˆ¶
- è¨“ç·´è³‡æ–™ç«Ÿç„¶æœ‰ 1,798,484 + 945 = 1,799,429 ç­†ï¼
```

**å•é¡Œï¼šæ¨¡å‹åœ¨è¨“ç·´æ™‚ä½¿ç”¨äº†æ‰€æœ‰ç‰¹å¾µè³‡æ–™ï¼ˆåŒ…å«é æ¸¬ç›®æ¨™å¸³æˆ¶ï¼‰ï¼**

é€™å°è‡´ï¼š
1. âŒ **Data Leakage**: é æ¸¬ç›®æ¨™å¸³æˆ¶ä¹Ÿè¢«ç”¨ä¾†è¨“ç·´
2. âŒ **è¨“ç·´æ•ˆæœæ¥µå·®**: F1-Score åªæœ‰ 0.0176 (é€£è¨“ç·´é›†éƒ½é æ¸¬ä¸å¥½)
3. âŒ **è¦å‰‡éåº¦åš´æ ¼**: Precision åªæœ‰ 0.97% (99% éƒ½æ˜¯èª¤å ±)

---

## å•é¡Œ 2: æ¨¡å‹åœ¨è¨“ç·´é›†ä¸Šè¡¨ç¾å°±å¾ˆå·®

```
Training Performance (from rule_evaluation.json):
- Precision: 0.0106 (1.06%)  â† å¤ªä½ï¼
- Recall: 0.5037 (50.37%)    â† é‚„å¯ä»¥
- F1-Score: 0.0207 (2.07%)   â† æ¥µä½ï¼

Confusion Matrix:
          Predicted 0    Predicted 1
Actual 0:  1,753,874      44,610  (2.5% FP rate)
Actual 1:  469            476     (50% recall)
```

**åˆ†æï¼š**
- é æ¸¬äº† 45,086 å€‹ç•°å¸¸ï¼Œä½†åªå°äº† 476 å€‹
- æœ‰ 44,610 å€‹ False Positivesï¼ˆèª¤å ±ç‡æ¥µé«˜ï¼‰
- é€™è¡¨ç¤ºè¦å‰‡æœ¬èº«å°±ä¸æº–ç¢º

---

## å•é¡Œ 3: è¦å‰‡ç”Ÿæˆç­–ç•¥æœ‰èª¤

**ç•¶å‰ç­–ç•¥ï¼ˆrule_predictor.py line 114-118ï¼‰ï¼š**
```python
if alert_mean > normal_mean:
    operator = '>'
    threshold = normal_mean + normal_std  # å•é¡Œåœ¨é€™ï¼
```

**å•é¡Œï¼š**
- é–¾å€¼è¨­å®šç‚º `normal_mean + 1*std` å¤ªå¯¬é¬†
- å°è‡´å¤§é‡æ­£å¸¸å¸³æˆ¶è¢«èª¤åˆ¤ç‚ºç•°å¸¸
- æ‡‰è©²ä½¿ç”¨æ›´åš´æ ¼çš„æ¨™æº–ï¼ˆå¦‚ 2-3 å€‹æ¨™æº–å·®ï¼‰

**è­‰æ“šï¼š**
```
å¾ feature_comparison.csv:
max_daily_in_txn:
  - Alert mean: 4.45, std: 8.45
  - Normal mean: 0.78, std: 1.25
  - ç•¶å‰é–¾å€¼: 0.78 + 1.25 = 2.03
  - ä½†é€™æ¨£æœƒæ¶µè“‹å¤ªå¤šæ­£å¸¸å¸³æˆ¶ï¼
```

---

## å•é¡Œ 4: ç‰¹å¾µé–¾å€¼è¨­å®šä¸åˆç†

çœ‹ `final_rules.json` çš„è¦å‰‡ï¼š
```json
{
  "feature": "avg_daily_txn",
  "operator": ">",
  "threshold": 1.939  // normal_mean + 1*std
}
```

ä½†å¾è³‡æ–™åˆ†å¸ƒçœ‹ï¼š
- Normal mean: 1.15, std: 0.79
- Alert mean: 3.30, std: 4.07
- é–¾å€¼ 1.94 å¤ªä½äº†ï¼æ‡‰è©²è‡³å°‘ 2.5-3.0

---

## å•é¡Œ 5: è¨“ç·´/é æ¸¬è³‡æ–™åˆ†é›¢éŒ¯èª¤

**æ‡‰è©²é€™æ¨£åšï¼š**
```
1. åªç”¨ acct_alert.csv (1,004) ä½œç‚ºæ­£æ¨£æœ¬
2. å¾å…¶ä»–å¸³æˆ¶éš¨æ©ŸæŠ½æ¨£ä½œç‚ºè² æ¨£æœ¬ï¼ˆå¦‚ 5,000-10,000 ç­†ï¼‰
3. åœ¨é€™å€‹å°è³‡æ–™é›†ä¸Šè¨“ç·´
4. ç„¶å¾Œé æ¸¬ acct_predict.csv
```

**å¯¦éš›åšäº†ä»€éº¼ï¼š**
```
1. æå–äº†æ‰€æœ‰å¸³æˆ¶çš„ç‰¹å¾µï¼ˆ180 è¬ç­†ï¼ï¼‰
2. åœ¨æ‰€æœ‰è³‡æ–™ä¸Šè¨“ç·´ï¼ˆåŒ…å«é æ¸¬ç›®æ¨™ï¼‰
3. é–¾å€¼åœ¨è¨“ç·´é›†ä¸Šå„ªåŒ–
4. ç„¶å¾Œåœ¨åŒæ¨£çš„è³‡æ–™ä¸Šé æ¸¬
â†’ é€™æ˜¯åš´é‡çš„è³‡æ–™æ´©æ¼ï¼
```

---

## è§£æ±ºæ–¹æ¡ˆ

### ğŸ”§ ç«‹å³ä¿®æ­£æ–¹æ¡ˆ

#### 1. ä¿®æ­£è¨“ç·´æµç¨‹ï¼ˆæœ€é‡è¦ï¼‰

**ä¿®æ”¹ `rule_predictor.py` çš„ `build_and_evaluate_predictor`ï¼š**

```python
def build_and_evaluate_predictor(
    features_df: pd.DataFrame,
    alert_accounts: set,
    comparison_df: pd.DataFrame,
    output_dir: str = 'output'
) -> RuleBasedPredictor:
    
    # ğŸ”´ é—œéµä¿®æ”¹ï¼šä¸è¦åœ¨æ‰€æœ‰è³‡æ–™ä¸Šè¨“ç·´ï¼
    # åªç”¨æœ‰æ¨™ç±¤çš„è³‡æ–™è¨“ç·´ï¼ˆalert + random normal sampleï¼‰
    
    # 1. åˆ†é›¢æœ‰æ¨™ç±¤å’Œç„¡æ¨™ç±¤è³‡æ–™
    alert_df = features_df[features_df['acct'].isin(alert_accounts)]
    unlabeled_df = features_df[~features_df['acct'].isin(alert_accounts)]
    
    # 2. å¾ç„¡æ¨™ç±¤è³‡æ–™ä¸­æŠ½æ¨£ä½œç‚ºè² æ¨£æœ¬ï¼ˆä¸åŒ…å«é æ¸¬ç›®æ¨™ï¼‰
    predict_accounts = load_predict_accounts('raw_data/acct_predict.csv')['acct']
    
    # å¾éé æ¸¬ç›®æ¨™ä¸­æŠ½æ¨£
    available_normal = unlabeled_df[~unlabeled_df['acct'].isin(predict_accounts)]
    normal_sample = available_normal.sample(
        n=min(len(alert_accounts) * 3, len(available_normal)),
        random_state=42
    )
    
    # 3. æ§‹å»ºè¨“ç·´é›†
    train_df = pd.concat([alert_df, normal_sample])
    train_df['is_alert'] = train_df['acct'].isin(alert_accounts).astype(int)
    
    # 4. åœ¨è¨“ç·´é›†ä¸Šå»ºç«‹è¦å‰‡...
```

#### 2. ä¿®æ­£é–¾å€¼è¨­å®šç­–ç•¥

**ä¿®æ”¹ `add_rules_from_comparison` ä¸­çš„é–¾å€¼è¨ˆç®—ï¼š**

```python
# ç•¶å‰ï¼ˆå¤ªå¯¬é¬†ï¼‰ï¼š
threshold = normal_mean + normal_std

# æ”¹ç‚ºï¼ˆæ›´åš´æ ¼ï¼‰ï¼š
threshold = normal_mean + 2.0 * normal_std  # 2 å€‹æ¨™æº–å·®
# æˆ–ä½¿ç”¨ç™¾åˆ†ä½æ•¸ï¼š
threshold = normal_p95  # ç¬¬ 95 ç™¾åˆ†ä½æ•¸
```

#### 3. å¢åŠ è¦å‰‡éæ¿¾

**åªé¸æ“‡é«˜å“è³ªè¦å‰‡ï¼š**

```python
# åœ¨ add_rules_from_comparison ä¸­åŠ å…¥ï¼š
significant = comparison_df[
    (comparison_df['p_value'] < 0.01) &      # æ›´åš´æ ¼çš„ p-value
    (abs(comparison_df['effect_size']) > 1.0) &  # æ›´å¤§çš„æ•ˆæ‡‰é‡
    (comparison_df['diff_ratio'] > 2.0)      # Alert/Normal æ¯”ä¾‹è¦ > 2
].copy()
```

#### 4. ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹

**è€ƒæ…®ç”¨æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ä»£æ›¿è¦å‰‡ï¼š**

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

# åœ¨è¨“ç·´é›†ä¸Šè¨“ç·´
rf = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_leaf=20,
    class_weight='balanced',
    random_state=42
)

# ä½¿ç”¨äº¤å‰é©—è­‰
scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='f1')
print(f"CV F1-Score: {scores.mean():.4f}")
```

---

## é æœŸæ”¹å–„

### ä¿®æ­£å‰ï¼ˆç•¶å‰ï¼‰ï¼š
- Training F1: 0.0207
- Test F1: 0.0724
- å¤§é‡èª¤å ±ï¼ˆPrecision 1.06%ï¼‰

### ä¿®æ­£å¾Œï¼ˆé æœŸï¼‰ï¼š
- Training F1: 0.3-0.5 (proper training)
- Test F1: 0.25-0.40 (realistic)
- Precision: > 20% (æ¸›å°‘èª¤å ±)
- Recall: 40-60% (ç¶­æŒæª¢å‡ºç‡)

---

## è¡Œå‹•è¨ˆç•«

1. âœ… **ç«‹å³ä¿®æ­£è¨“ç·´æµç¨‹**ï¼ˆåˆ†é›¢è¨“ç·´/æ¸¬è©¦è³‡æ–™ï¼‰
2. âœ… **èª¿æ•´é–¾å€¼ç­–ç•¥**ï¼ˆä½¿ç”¨ 2-3 å€‹æ¨™æº–å·®ï¼‰
3. âœ… **è€ƒæ…®ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’æ¨¡å‹**ï¼ˆRandom Forest / XGBoostï¼‰
4. âœ… **é€²è¡Œé©ç•¶çš„äº¤å‰é©—è­‰**
5. âœ… **é‡æ–°è¨“ç·´ä¸¦è©•ä¼°**

---

## çµè«–

ç•¶å‰æ¨¡å‹çš„å•é¡Œæ˜¯**ç³»çµ±æ€§çš„**ï¼š
1. è³‡æ–™æ´©æ¼ï¼ˆè¨“ç·´é›†åŒ…å«é æ¸¬ç›®æ¨™ï¼‰
2. è¦å‰‡ç”Ÿæˆç­–ç•¥éæ–¼å¯¬é¬†
3. æ²’æœ‰é©ç•¶çš„è¨“ç·´/æ¸¬è©¦åˆ†é›¢

**é€™è§£é‡‹äº†ç‚ºä»€éº¼èª¿æ•´é–¾å€¼æ²’æœ‰å¹«åŠ©** - å•é¡Œåœ¨æ¨¡å‹æœ¬èº«ï¼Œä¸åœ¨é æ¸¬é–¾å€¼ï¼

å¿…é ˆé‡æ–°è¨­è¨ˆè¨“ç·´æµç¨‹æ‰èƒ½å¾—åˆ°æœ‰æ•ˆçš„æ¨¡å‹ã€‚

